# Отчет по исследованию характеристик случайных графов

## Часть 1: Описание кода и алгоритмов

### Используемые инструменты
- **Python 3.11** с ключевыми библиотеками:
  - `numpy` - генерация случайных выборок
  - `networkx` - работа с графами
  - `sklearn.neighbors` - построение KNN-графов
  - `scipy.stats` - статистические тесты
  - `matplotlib` - визуализация результатов
  - `pandas` - обработка табличных данных

### Реализованные функции

#### Генераторы выборок
1. **`sample_exp(n, lam)`**  
   Генерирует выборку размера `n` из экспоненциального распределения с параметром `lam`.  
   Алгоритм: `numpy.random.exponential(1/lam, n)`

2. **`sample_gamma(n, shape, lam)`**  
   Генерирует выборку размера `n` из гамма-распределения с параметрами формы `shape` и интенсивности `lam`.  
   Алгоритм: `numpy.random.gamma(shape, 1/lam, n)`

3. **`sample_normal(n, sigma)`**  
   Генерирует выборку размера `n` из нормального распределения N(0, σ²).

4. **`sample_t(n, df)`**  
   Генерирует выборку размера `n` из t-распределения с `df` степенями свободы.

#### Построители графов
5. **`build_knn_graph(X, k)`**  
   Строит KNN-граф по одномерной выборке `X`:
   - Использует `NearestNeighbors` для поиска k+1 ближайших соседей
   - Создает рёбра между точкой и её k соседями
   - Возвращает невзвешенный неориентированный граф

6. **`build_dist_graph(X, d)`**  
   Строит DIST-граф по одномерной выборке `X`:
   - Соединяет точки i и j если |X[i] - X[j]| ≤ d
   - Полный перебор всех пар точек (O(n²))

#### Характеристики графов
7. **`count_triangles(G)`**  
   Вычисляет количество треугольников в графе:  
   `sum(nx.triangles(G).values()) // 3`

8. **`chromatic_number(G)`**  
   Вычисляет хроматическое число с помощью жадного алгоритма:  
   `nx.coloring.greedy_color(G, strategy='largest_first')`

9. **`clique_number(G)`**  
   Находит размер максимальной клики:  
   `len(max(nx.find_cliques(G), key=len))`

10. **Другие характеристики**:  
    - `max_degree`/`min_degree` - экстремальные степени вершин
    - `count_components` - число компонент связности
    - `count_articulation_points` - точки сочленения
    - `max_independent_set_size` - размер макс. независимого множества
    - `domination_number` - число доминирования

#### Экспериментальные методы
11. **`monte_carlo_characteristic(...)`**  
    Проводит Монте-Карло симуляцию:
    - Генерирует `n_sim` выборок через `sample_func`
    - Строит графы через `graph_func`
    - Вычисляет характеристику через `char_func`
    - Возвращает массив значений характеристики

12. **`generate_dataset(...)`**  
    Генерирует датасет для бинарной классификации:
    - Создает выборки для H0 и H1 распределений
    - Вычисляет заданные характеристики графов
    - Возвращает DataFrame с метками классов

#### Аналитические функции
13. **`analyze_characteristic(...)`**  
    Анализирует распределение характеристики:
    - Вычисляет AUC ROC и порог (95% для H0)
    - Строит гистограммы распределений
    - Рассчитывает ошибку I рода и мощность
   
## Часть 2: Эксперименты и результаты

### Эксперимент 1: KNN-граф (число треугольников)
**Цель**: Исследовать влияние параметров k и n на различение распределений Exp(λ=1) и Γ(½, λ=√½)

**Параметры**:
- n = [100, 200, 500, 1000]
- k = [2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90]
- 300 симуляций для каждой конфигурации

**Вывод**

* Разделимость H0 и H1
  - При k ≤ 10 — AUC ROC ≈ 0.5, различия между H0 и H1 незначимы.
  - При k ≥ 20 — AUC ROC начинает расти, при k=40 достигает почти идеального результата.
  - При k ≥ 60 — AUC ROC ≈ 1.0, полное разделение, отличная работа.

* Ошибка 1 рода и мощность
  
При всех k ошибка 1 рода ≈ 0.05 (контроль α).

Мощность растёт с увеличением k.

При k=40 — мощность ≈ 0.84.

При k ≥ 60 — мощность ≈ 1.0.

* Итог

Эффективность растёт с увеличением k и n

* Пороговые значения:

  - k < 20: AUC ≈ 0.5 (неэффективно)
  - k ≥ 40: AUC > 0.9 (высокая эффективность)
  - k ≥ 60: AUC = 1.0 (идеальное различение)

Ошибка I рода стабильно ≈0.05

### Эксперимент 2: KNN-граф с вариацией параметров
**Цель:** Проверить устойчивость характеристики при изменении λ в распределениях

**Параметры:**

- n = 1000
- k = 60
- λ_H0 = λ_H1 = [0.3, 0.5, 1.0, 1.5, 2.0, 3.0]

**Вывод**
- При n = 200 и k = 60 вне зависимости от параметров распределений мощность остается выше 0.94, AUC не ниже 0.98. значит характеристика - число треугольников работает отлично.

### Эксперимент 3: DIST-граф (хроматическое число)
**Цель:** Исследовать влияние параметров d и n на различение распределений

**Параметры:**

- n = [100, 200, 500, 1000]
- d = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 1.0, 2.0]

**Вывод**

- Лучшие результаты при d ≤ 0.3
- Эффективность падает при d > 0.7
- Размер выборки слабо влияет на качество

### Эксперимент 4: DIST-граф с вариацией параметров
**Цель:** Проверить устойчивость при изменении λ в распределениях

**Параметры:**

- n = 200
- d = 0.3
- λ_H0, λ_H1 = [0.3, 0.5, 1.0, 1.5, 2.0, 3.0]

**Вывод**

- Высокая эффективность при λ_H0 < 1.5
- Полная потеря эффективности при:
  * λ_H0 ≥ 1.5 и λ_H1 ≤ 0.5
  * λ_H0 ≥ 3.0 и λ_H1 ≤ 1.0
- Критерий чувствителен к соотношению параметров

### Эксперимент 5: KNN-граф (число компонент связности)
**Цель:** Исследовать влияние параметров n и k на различение нормального распределения (H0) и распределения Стьюдента (H1).

**Параметры:**

- n = [100, 200, 500]
- k = [2, 3, 4, 5, 10, 20, 40, 80]
- σ_H0 = 1 (нормальное распределение)
- ν_H1 = 3 (распределение Стьюдента)

**Вывод:**

- Для KNN-графа мощность критерия (Power) оставалась крайне низкой (менее 0.1) при всех комбинациях n и k.
- Наилучшие результаты (Power ~0.11) наблюдались при n=100 и k=3, но этого недостаточно для надежного различения распределений.
- Характеристика "число компонент связности" неэффективна для KNN-графа в данном контексте.

### Эксперимент 6: DIST-граф (размер максимального независимого множества)
**Цель:** Исследовать влияние параметров n и d на различение нормального распределения (H0) и распределения Стьюдента (H1).

**Параметры:**

- n = [100, 200, 500]
- d = [0.1, 0.2, 0.5, 1.0]
- σ_H0 = 1 (нормальное распределение)
- ν_H1 = 3 (распределение Стьюдента)

**Вывод:**

- Для DIST-графа мощность критерия (Power) была близка к 1 при всех значениях n и d, особенно для n ≥ 200.
- Наилучшие результаты достигались при d=0.1 и d=0.2, где Power=1.0 даже для n=100.
- Характеристика "размер максимального независимого множества" отлично справляется с различением распределений.

### Эксперимент 7: Влияние параметров распределений (фиксированные n, k, d)
**Цель:** Исследовать, как изменение параметров σ_H0 (нормальное распределение) и ν_H1 (распределение Стьюдента) влияет на мощность критерия.

**Параметры:**

- n = 200
- k = 4 (для KNN), d = 0.2 (для DIST)
- σ_H0 = [0.2, 0.5, 0.7, 1, 1.5, 2, 3, 5]
- ν_H1 = [1.5, 2, 3, 5, 10, 20]

**Вывод для KNN:**

- Мощность оставалась низкой (Power < 0.1) для всех комбинаций σ_H0 и ν_H1.
- Максимальная Power=0.08 наблюдалась при σ_H0=0.5 и ν_H1=20.

** Вывод для DIST: **

- Мощность была высокой (Power ≥ 0.99) при σ_H0 ≤ 1 и любых ν_H1.
- При увеличении σ_H0 (например, до 2 или 3) мощность резко падала, особенно для ν_H1 ≥ 3.
- Критерий наиболее эффективен при малых σ_H0 (≤ 1) и любых ν_H1.

### Эксперимент 8: Визуализация результатов (тепловые карты)
**Цель:** Наглядно представить зависимость мощности критерия от параметров n, k/d, σ_H0 и ν_H1.

**Параметры:**

- Для KNN: n, k, σ_H0, ν_H1.
- Для DIST: n, d, σ_H0, ν_H1.

**Вывод:**

- Тепловые карты подтвердили, что DIST-граф значительно превосходит KNN-граф по мощности критерия.
- Для DIST-графа мощность высока при малых σ_H0 и любых ν_H1, тогда как для KNN-графа мощность стабильно низкая.

### Общие выводы:

- KNN-граф: Характеристика "число компонент связности" неэффективна для различения нормального распределения и распределения Стьюдента.
- DIST-граф: Характеристика "размер максимального независимого множества" демонстрирует высокую мощность, особенно при малых σ_H0 (≤ 1) и любых ν_H1.
- Рекомендации: Для задач различения распределений предпочтительно использовать DIST-граф с малыми значениями d (≤ 0.3) и учитывать параметры распределений (σ_H0 и ν_H1).
