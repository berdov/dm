{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e2e8eb",
   "metadata": {},
   "source": [
    "# Анализ характеристик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447fc8a",
   "metadata": {},
   "source": [
    "- Я хочу выбрать для анализа DIST-граф, в первой части он оказался более эффективен. Первым делом переберу все характеристики и оценю их мощность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef6566f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/Users/berdov/dm_pr/dm/src/functions.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "import importlib\n",
    "import functions\n",
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45cf97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import chromatic_number\n",
    "from functions import clique_number\n",
    "from functions import max_independent_set_size\n",
    "from functions import domination_number\n",
    "from functions import clique_cover_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2bbb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import (\n",
    "    build_dist_graph,\n",
    "    sample_gamma,\n",
    "    sample_exp,\n",
    "    monte_carlo_characteristic\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a2778",
   "metadata": {},
   "source": [
    "- теперь мы готовы к анализу характеристик и оценке того, как они меняются с ростом n. В качестве d возьмем 0.1, он показал себя лучше остальных в 1 части эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b52ec0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ: Хроматическое число\n",
      "Анализ: Кликовое число\n",
      "Анализ: Макс. независимое множество\n",
      "Анализ: Доминирование\n",
      "Анализ: Кликовое покрытие\n",
      "Анализ: Хроматическое число\n",
      "Анализ: Кликовое число\n",
      "Анализ: Макс. независимое множество\n",
      "Анализ: Доминирование\n",
      "Анализ: Кликовое покрытие\n",
      "Анализ: Хроматическое число\n",
      "Анализ: Кликовое число\n",
      "Анализ: Макс. независимое множество\n",
      "Анализ: Доминирование\n",
      "Анализ: Кликовое покрытие\n",
      "Анализ: Хроматическое число\n",
      "Анализ: Кликовое число\n",
      "Анализ: Макс. независимое множество\n",
      "Анализ: Доминирование\n",
      "Анализ: Кликовое покрытие\n",
      "Анализ: Хроматическое число\n",
      "Анализ: Кликовое число\n",
      "Анализ: Макс. независимое множество\n",
      "Анализ: Доминирование\n",
      "Анализ: Кликовое покрытие\n",
      "      n               Характеристика  AUC ROC  Power (H1)  Порог (95% H0)\n",
      "0    10          Хроматическое число    0.705       0.155            4.00\n",
      "1    10               Кликовое число    0.744       0.200            4.00\n",
      "2    10  Макс. независимое множество    0.723       0.105            8.00\n",
      "3    10                Доминирование    0.453       0.000           10.00\n",
      "4    10            Кликовое покрытие    0.710       0.160            4.00\n",
      "5    25          Хроматическое число    0.906       0.480            7.00\n",
      "6    25               Кликовое число    0.908       0.705            6.05\n",
      "7    25  Макс. независимое множество    0.815       0.215           13.00\n",
      "8    25                Доминирование    0.514       0.000           25.00\n",
      "9    25            Кликовое покрытие    0.893       0.600            6.00\n",
      "10  100          Хроматическое число    1.000       1.000           18.00\n",
      "11  100               Кликовое число    1.000       1.000           17.00\n",
      "12  100  Макс. независимое множество    0.790       0.125           24.00\n",
      "13  100                Доминирование    0.600       0.000          100.00\n",
      "14  100            Кликовое покрытие    0.999       0.995           17.00\n",
      "15  200          Хроматическое число    1.000       1.000           29.00\n",
      "16  200               Кликовое число    1.000       1.000           28.05\n",
      "17  200  Макс. независимое множество    0.720       0.080           29.00\n",
      "18  200                Доминирование    0.596       0.065          199.05\n",
      "19  200            Кликовое покрытие    1.000       1.000           28.05\n",
      "20  500          Хроматическое число    1.000       1.000           64.00\n",
      "21  500               Кликовое число    1.000       1.000           61.05\n",
      "22  500  Макс. независимое множество    0.648       0.135           36.00\n",
      "23  500                Доминирование    0.598       0.075          497.05\n",
      "24  500            Кликовое покрытие    1.000       1.000           61.00\n"
     ]
    }
   ],
   "source": [
    "n = [10, 25, 100, 200, 500]\n",
    "d = 0.1\n",
    "n_sim = 200\n",
    "alpha = 0.05\n",
    "\n",
    "characteristics = {\n",
    "    'Хроматическое число': chromatic_number,\n",
    "    'Кликовое число': clique_number,\n",
    "    'Макс. независимое множество': max_independent_set_size,\n",
    "    'Доминирование': domination_number,\n",
    "    'Кликовое покрытие': clique_cover_number\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "for n in n:\n",
    "    for name, func in characteristics.items():\n",
    "        print(f\"Анализ: {name}\")\n",
    "        lambda_H0 = 0.5**0.5\n",
    "        lambda_H1 = 1\n",
    "        X0_raw = monte_carlo_characteristic(sample_gamma, lambda X: build_dist_graph(X, d), func, 0.5, lambda_H0, n=n, n_sim=n_sim)\n",
    "        X1_raw = monte_carlo_characteristic(sample_exp, lambda X: build_dist_graph(X, d), func, lambda_H1, n=n, n_sim=n_sim)\n",
    "        if np.median(X0_raw) < np.median(X1_raw):\n",
    "            T_H0, T_H1 = X0_raw, X1_raw\n",
    "        else:\n",
    "            T_H0, T_H1 = X1_raw, X0_raw\n",
    "\n",
    "        threshold = np.percentile(T_H0, 100 * (1 - alpha))\n",
    "        power = np.mean(T_H1 > threshold)\n",
    "        auc = roc_auc_score([0]*len(T_H0) + [1]*len(T_H1), np.concatenate([T_H0, T_H1]))\n",
    "        summary.append({\n",
    "            'n': n,\n",
    "            'Характеристика': name,\n",
    "            'AUC ROC': round(auc, 3),\n",
    "            'Power (H1)': round(power, 3),\n",
    "            'Порог (95% H0)': round(threshold, 2)\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa805b99",
   "metadata": {},
   "source": [
    "# Вывод при росте n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28dac2",
   "metadata": {},
   "source": [
    "- заметим, что каждый из критериев повышал свою эффективность при росте n, кроме размера максимального независимого множества. Удивительно, но его мощность лишь падает. Заметим что при n=500/200 у нас есть аж три критерия с мощностью 1. Значит мы уж точно справимся с построением качественных моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8bc29",
   "metadata": {},
   "source": [
    "- теперь стало понятно как строить модель. Давайте сравним 4 модели и выберем лучшую из них, также будем анализировать результаты при разных N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5adff410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      n               Модель  AUC Mean  AUC Std  Accuracy Mean  Accuracy Std  \\\n",
      "0    25        Random Forest     0.905    0.027          0.817         0.050   \n",
      "1    25  Logistic Regression     0.930    0.022          0.845         0.030   \n",
      "2    25            SVM (RBF)     0.929    0.024          0.847         0.041   \n",
      "3    25        Decision Tree     0.788    0.052          0.778         0.040   \n",
      "4   100        Random Forest     0.997    0.005          0.995         0.006   \n",
      "5   100  Logistic Regression     1.000    0.000          0.995         0.006   \n",
      "6   100            SVM (RBF)     1.000    0.000          0.995         0.006   \n",
      "7   100        Decision Tree     0.988    0.014          0.988         0.014   \n",
      "8   500        Random Forest     1.000    0.000          1.000         0.000   \n",
      "9   500  Logistic Regression     1.000    0.000          1.000         0.000   \n",
      "10  500            SVM (RBF)     1.000    0.000          1.000         0.000   \n",
      "11  500        Decision Tree     1.000    0.000          1.000         0.000   \n",
      "\n",
      "    Power  Type I Error  \n",
      "0    0.79          0.24  \n",
      "1    0.81          0.22  \n",
      "2    0.80          0.21  \n",
      "3    0.77          0.25  \n",
      "4    1.00          0.01  \n",
      "5    1.00          0.01  \n",
      "6    1.00          0.01  \n",
      "7    1.00          0.01  \n",
      "8    1.00          0.00  \n",
      "9    1.00          0.00  \n",
      "10   1.00          0.00  \n",
      "11   1.00          0.00  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM (RBF)\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "n_sim = 200\n",
    "d = 0.1\n",
    "n_values = [25, 100, 500]\n",
    "\n",
    "feature_funcs = [\n",
    "    max_independent_set_size,\n",
    "    domination_number,\n",
    "    clique_number,\n",
    "    chromatic_number,\n",
    "    clique_cover_number\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in n_values:\n",
    "    df_train = generate_dataset(\n",
    "        n=n,\n",
    "        d=d,\n",
    "        dist_H0=sample_gamma,\n",
    "        args_H0=(0.5, 0.5**0.5),\n",
    "        dist_H1=sample_exp,\n",
    "        args_H1=(1,),\n",
    "        feature_funcs=feature_funcs,\n",
    "        graph_func=lambda X: build_dist_graph(X, d),\n",
    "        n_sim=n_sim\n",
    "    )\n",
    "\n",
    "    X_train = df_train.drop(\"label\", axis=1)\n",
    "    y_train = df_train[\"label\"]\n",
    "\n",
    "    df_H0 = generate_dataset(n=n, d=d, dist_H0=sample_gamma, args_H0=(0.5, 0.5**0.5),\n",
    "                             dist_H1=sample_exp, args_H1=(1,),\n",
    "                             feature_funcs=feature_funcs,\n",
    "                             graph_func=lambda X: build_dist_graph(X, d),\n",
    "                             n_sim=100).query(\"label == 0\")\n",
    "\n",
    "    df_H1 = generate_dataset(n=n, d=d, dist_H0=sample_gamma, args_H0=(0.5, 0.5**0.5),\n",
    "                             dist_H1=sample_exp, args_H1=(1,),\n",
    "                             feature_funcs=feature_funcs,\n",
    "                             graph_func=lambda X: build_dist_graph(X, d),\n",
    "                             n_sim=100).query(\"label == 1\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        auc_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "        acc_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "        clf = model.__class__(**model.get_params())\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_H0 = clf.predict(df_H0.drop(\"label\", axis=1))\n",
    "        y_pred_H1 = clf.predict(df_H1.drop(\"label\", axis=1))\n",
    "\n",
    "        type1 = np.mean(y_pred_H0 == 1)\n",
    "        power = np.mean(y_pred_H1 == 1)\n",
    "\n",
    "        results.append({\n",
    "            \"n\": n,\n",
    "            \"Модель\": name,\n",
    "            \"AUC Mean\": round(np.mean(auc_scores), 3),\n",
    "            \"AUC Std\": round(np.std(auc_scores), 3),\n",
    "            \"Accuracy Mean\": round(np.mean(acc_scores), 3),\n",
    "            \"Accuracy Std\": round(np.std(acc_scores), 3),\n",
    "            \"Power\": round(power, 3),\n",
    "            \"Type I Error\": round(type1, 3)\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e60a25",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340bbad",
   "metadata": {},
   "source": [
    "- для начала выберем лучшую модель. При n = 500 все модели отработали просто идеально, все показатели равны твердой единичке. Заметим, при n = 100 также power=1, при этом верояность ошибки стала 0.01 у всех 4х моделей, LogReg и SVM отработали чуть лучше, у них дисперсия по AUC = 0 и наименьшая по критерию Accuracy.  При n = 25 все модели отработали хуже, но это проблематика размера выборки. LogReg и SVM в очередной раз справились чуть лучше. В качестве победителя выявим LogReg, у нее самая высокая мощность (0.81) и самая маленкьая дисперсия Accuracy (0.03). К сожалению вероятность ошибки 1 рода = 0.21, но все равно результаты просто прекрасные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ed7df",
   "metadata": {},
   "source": [
    "# Главный вывод: все модели справились очень хорошо"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
